{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0ff3309",
   "metadata": {},
   "source": [
    "# Creating a MOCK dataset \n",
    "Author: Karina Condeixa\n",
    "__________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8be3b9",
   "metadata": {},
   "source": [
    "The process to create a fake dataset started by making dataframes about `users` and `item`, and further a complete dataframe that could be used in the `model`.\n",
    "\n",
    "`numpy random` and `faker` were used to ccreate randomized series. Latitude_longitude points were picked using a polygons method, consideing four points choosen manually in Google Maps.\n",
    "\n",
    "Dependent variables are part of a same series, identified by underscore.\n",
    "\n",
    "Addresses are illustrative, they are addresses from all over Germany. This is a limitation of the Faker package, which only considers countries, and does not have data for Berlin.\n",
    "\n",
    "_________________________________\n",
    "\n",
    "**TODO:**\n",
    "- split geopoints into lat and lng files for users\n",
    "- split geopoints into lat and lng files for items\n",
    "- create final dataset, organising by columns\n",
    "- save the files as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "5066ea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "from faker import Faker, providers\n",
    "from faker.providers.address.de_DE import Provider as DeDeAddressProvider\n",
    "from faker.generator import random\n",
    "from faker.providers import BaseProvider\n",
    "# import random\n",
    "\n",
    "import folium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75af7841",
   "metadata": {},
   "source": [
    "### Postcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "10760793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xs/pmxwbppj14b4v76l4llp17n80000gp/T/ipykernel_13057/140568398.py:4: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis([\"postcodes_berlin\"], axis=1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# immport and clean original dataset removing poostcodes from Germanay, that are not in Berlin\n",
    "postcodes_de = pd.read_excel(r'data/German-Zip-Codes.xlsx', sheet_name='Berlin')\n",
    "df = pd.DataFrame(postcodes_de)\n",
    "df.set_axis([\"postcodes_berlin\"], axis=1,inplace=True)\n",
    "df = (df[\"postcodes_berlin\"].str[8:-11])\n",
    "df.to_csv('postcodes_berlin.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93845160",
   "metadata": {},
   "source": [
    "### Creating the postcode series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b5c4f1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     postcodes_berlin\n",
      "0               10117\n",
      "1               10119\n",
      "2               10178\n",
      "3               10179\n",
      "4               10243\n",
      "..                ...\n",
      "184             14169\n",
      "185             14193\n",
      "186             14195\n",
      "187             14197\n",
      "188             14199\n",
      "\n",
      "[189 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# import postcodes from Berlin and create a dataframe removing indexes and headers\n",
    "postcodes_berlin = pd.read_csv('data/postcodes_berlin.csv')\n",
    "print(postcodes_berlin)\n",
    "postcodes_berlin_series = postcodes_berlin[:][1:].squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501abd94",
   "metadata": {},
   "source": [
    "### Creating lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93059002",
   "metadata": {},
   "source": [
    "#### lat lng : choosing random point based on a polygon\n",
    "reference: \n",
    "    A quick trick to create random lat/long coordinates in python (within a defined polygon)\n",
    "https://medium.com/the-data-journal/a-quick-trick-to-create-random-lat-long-coordinates-in-python-within-a-defined-polygon-e8997f05123a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c6152d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Modules\n",
    "import numpy as np\n",
    "import random\n",
    "# Use 'conda install shapely' to import the shapely library.\n",
    "from shapely.geometry import Polygon, Point\n",
    "\n",
    "num_records = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc658e66",
   "metadata": {},
   "source": [
    "### Creating the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "9fab278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: # multi_locale_generator = Faker(['it_IT', 'en_US', 'de-DE', 'pt_BR', 'es-ES', 'fr-FR', 'ru-RU', 'tr-TR'])\n",
    "\n",
    "# Instantiate Faker with multiple locales\n",
    "german_locale_generator = Faker(['de_DE'])\n",
    "fake = Faker()\n",
    "Faker.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e7d3c6fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "f926b4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.51468923314108 , 13.443433496679852\n",
      "52.48083455387833 , 13.324635956781632\n",
      "52.54068013426472 , 13.348663709485534\n",
      "52.526450026590865 , 13.517410349162015\n",
      "52.47926254962274 , 13.41680634766404\n",
      "52.52525214023197 , 13.478763560118274\n",
      "52.545200100761996 , 13.292108640382077\n",
      "52.546826551287495 , 13.333600167524281\n",
      "52.515011473059054 , 13.604610508684335\n",
      "52.49998179940619 , 13.400180189057899\n"
     ]
    }
   ],
   "source": [
    "# Define the desired polygon : points choosen in Google maps\n",
    "\n",
    "poly = Polygon([(52.645883, 13.395869), \n",
    "                (52.526568, 13.645808),\n",
    "                (52.381789, 13.405482),\n",
    "                (52.484773, 13.136317)])\n",
    "\n",
    "\n",
    "min_x = 52.381789\n",
    "max_x = 52.645883\n",
    "min_y = 13.136317\n",
    "max_y = 13.645808\n",
    "\n",
    "# Defining the randomization generator\n",
    "def polygon_random_points (poly, num_records):\n",
    "    min_x, min_y, max_x, max_y = poly.bounds\n",
    "    points = []\n",
    "    while len(points) < num_records:\n",
    "        random_point = Point([random.uniform(min_x, max_x), random.uniform(min_y, max_y)])\n",
    "        if (random_point.within(poly)):\n",
    "            points.append(random_point)\n",
    "    return points\n",
    "    # Choose the number of points desired. T\\ \n",
    "points = polygon_random_points(poly,num_records)\n",
    "# Testing the results.\n",
    "for p in points:\n",
    "    print(p.x,\",\",p.y)\n",
    "\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee859f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5646776",
   "metadata": {},
   "source": [
    "### The polygon in the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "b30af939",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapObj = folium.Map(location=[52.520008,13.404954], zoom_start=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "6c1b8cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "folium.Polygon([(52.645883, 13.395869), \n",
    "                (52.526568, 13.645808), \n",
    "                (52.381789, 13.405482), \n",
    "                (52.484773, 13.136317)],\n",
    "                fill=True, \n",
    "                weight=3, \n",
    "                fill_color='orange',\n",
    "                color='green',\n",
    "                fill_opacity=0.8).add_to(mapObj)\n",
    "\n",
    "mapObj.save('output.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25096f71",
   "metadata": {},
   "source": [
    "### User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2606e7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to create user data\n",
    "\n",
    "user_type = ['giver', 'looker']\n",
    "\n",
    "\n",
    "def create_user_data(num_records): \n",
    "  \n",
    "    # dictionary \n",
    "    user ={} \n",
    "    for i in range(0, num_records): \n",
    "        user[i] = {} \n",
    "        user[i]['name'] = fake.name()\n",
    "#         user[i]['email'] = fake.email()\n",
    "#         user[i]['email'] = fake.ascii_free_email()\n",
    "        user[i]['email'] = fake.ascii_email()\n",
    "        user[i]['address'] = german_locale_generator.address()  # these addresses are from germany, find a list of address for berlin\n",
    "        user[i]['user_type'] = fake.random_element(user_type)\n",
    "        user[i]['user_lat_lng'] = polygon_random_points(poly,1)\n",
    "        user[i]['user_postcode'] = np.random.choice(postcodes_berlin_series)\n",
    "\n",
    "    return user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "45a27923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>address</th>\n",
       "      <th>user_type</th>\n",
       "      <th>user_lat_lng</th>\n",
       "      <th>user_postcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Norma Fisher</td>\n",
       "      <td>ysullivan@yahoo.com</td>\n",
       "      <td>Alwina-Etzold-Ring 19\\n89241 Sömmerda</td>\n",
       "      <td>looker</td>\n",
       "      <td>[POINT (52.49270299944904 13.2632600025517)]</td>\n",
       "      <td>13158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brian Hamilton</td>\n",
       "      <td>hramos@brown-sellers.com</td>\n",
       "      <td>Eleonore-Oderwald-Ring 51\\n93328 Bremen</td>\n",
       "      <td>giver</td>\n",
       "      <td>[POINT (52.55783661408981 13.27197206301923)]</td>\n",
       "      <td>13409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheri Bolton DDS</td>\n",
       "      <td>jasmine85@hotmail.com</td>\n",
       "      <td>Conradistr. 5/9\\n42320 Naila</td>\n",
       "      <td>giver</td>\n",
       "      <td>[POINT (52.59564570175657 13.40603977312539)]</td>\n",
       "      <td>10439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peter Mcdowell</td>\n",
       "      <td>villanuevasandra@vega.net</td>\n",
       "      <td>Salzring 7/5\\n59179 Erfurt</td>\n",
       "      <td>giver</td>\n",
       "      <td>[POINT (52.43368398014155 13.29297219220949)]</td>\n",
       "      <td>13057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Devin Thornton</td>\n",
       "      <td>marvincabrera@gmail.com</td>\n",
       "      <td>Margot-Ruppert-Allee 013\\n61510 Euskirchen</td>\n",
       "      <td>giver</td>\n",
       "      <td>[POINT (52.43427814851649 13.48465490616225)]</td>\n",
       "      <td>12309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name                      email  \\\n",
       "0      Norma Fisher        ysullivan@yahoo.com   \n",
       "1    Brian Hamilton   hramos@brown-sellers.com   \n",
       "2  Sheri Bolton DDS      jasmine85@hotmail.com   \n",
       "3    Peter Mcdowell  villanuevasandra@vega.net   \n",
       "4    Devin Thornton    marvincabrera@gmail.com   \n",
       "\n",
       "                                      address user_type  \\\n",
       "0       Alwina-Etzold-Ring 19\\n89241 Sömmerda    looker   \n",
       "1     Eleonore-Oderwald-Ring 51\\n93328 Bremen     giver   \n",
       "2                Conradistr. 5/9\\n42320 Naila     giver   \n",
       "3                  Salzring 7/5\\n59179 Erfurt     giver   \n",
       "4  Margot-Ruppert-Allee 013\\n61510 Euskirchen     giver   \n",
       "\n",
       "                                    user_lat_lng user_postcode  \n",
       "0   [POINT (52.49270299944904 13.2632600025517)]         13158  \n",
       "1  [POINT (52.55783661408981 13.27197206301923)]         13409  \n",
       "2  [POINT (52.59564570175657 13.40603977312539)]         10439  \n",
       "3  [POINT (52.43368398014155 13.29297219220949)]         13057  \n",
       "4  [POINT (52.43427814851649 13.48465490616225)]         12309  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_mock_df = pd.DataFrame(create_user_data(1000)).transpose()\n",
    "user_mock_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9b0feb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add user_ids \n",
    "user_mock_df['user_id'] = user_mock_df.index + 1\n",
    "user_id_series = user_mock_df['user_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65da01d1",
   "metadata": {},
   "source": [
    "### Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "d154b713",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_status = ['avaliable', 'not_available']\n",
    "item_condition = ['good','medium','bad']\n",
    "\n",
    "category_item = ['furniture-sofa',\n",
    "                 'furniture-armchair',\n",
    "                 'furniture-chair',\n",
    "                 'furniture-table',\n",
    "                 'furniture-desk',\n",
    "                 'furniture-bed',\n",
    "                 'furniture-bookcase',\n",
    "                 'furniture-bedside_table',\n",
    "                 'furniture-cabinet',\n",
    "                 'furniture-wardrobe',\n",
    "                 'furniture-shelf',\n",
    "                 'furniture-cupboard',\n",
    "                 'furniture-rollcontainers',\n",
    "                 'furniture-shoe_rack',\n",
    "                 'furniture-mirror',\n",
    "                 'furniture-cot',\n",
    "                 'furniture-trolley',\n",
    "                 'appliance-washing_machine',\n",
    "                 'appliance-dish_washer',\n",
    "                 'appliance-drying_rack',\n",
    "                 'appliance-refrigerator',\n",
    "                 'appliance-blender',\n",
    "                 'appliance-extractor_hood',\n",
    "                 'appliance-clothes_iron',\n",
    "                 'appliance-vacuum_cleaner',\n",
    "                 'appliance-sandwich_maker',\n",
    "                 'appliance-kettle',\n",
    "                 'appliance-air_conditioner',\n",
    "                 'appliance-heater',\n",
    "                 'appliance-pan',\n",
    "                 'appliance-popcorn_maker',\n",
    "                 'appliance-coffee_machine',\n",
    "                 'appliance-stove',\n",
    "                 'lighting-lighting',\n",
    "                 'lighting-chandelier',\n",
    "                 'lighting-lightbulb',\n",
    "                 'musical_equipment-guitar',\n",
    "                 'musical_equipment-sound_amplifier',\n",
    "                 'musical_equipment-contrabass',\n",
    "                 'musical_equipment-battery',\n",
    "                 'musical_equipment-piano',\n",
    "                 'tech-desktop',\n",
    "                 'tech-laptop',\n",
    "                 'tech-phone',\n",
    "                 'tech-keyboard',\n",
    "                 'clothes-woman_jacket',\n",
    "                 'clothes-man_jacket',\n",
    "                 'clothes-child_jacket',\n",
    "                 'clothes-woman_clothes',\n",
    "                 'clothes-man_clothes',\n",
    "                 'clothes-child_clothes',\n",
    "                 'shoes-woman_shoes',\n",
    "                 'shoes-man_shoes',\n",
    "                 'shoes-child_shoes',\n",
    "                 'miscelaneaous-ironing_board',\n",
    "                 'miscelaneaous-picture_frame',\n",
    "                 'miscelaneaous-bicycle',\n",
    "                 'miscelaneaous-plant',\n",
    "                 'miscelaneaous-carpet',\n",
    "                 'miscelaneaous-roller_skates',\n",
    "                 'miscelaneaous-ski_skates',\n",
    "                 'miscelaneaous-books',\n",
    "                 'miscelaneaous-purse',\n",
    "                 'miscelaneaous-suitcase',\n",
    "                 'miscelaneaous-shopping_venture',\n",
    "                 'miscelaneaous-board',\n",
    "                 'miscelaneaous-frame',\n",
    "                 'home-mattress', \n",
    "                 'home-carpet',\n",
    "                 'kids-stroller',\n",
    "                 'kids-baby_carriage']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "850728a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to create item data\n",
    "limit = '-30d'  # limit of 30 days of item in the app\n",
    "\n",
    "def create_item_data(num_records): \n",
    "  \n",
    "    # dictionary \n",
    "    item ={} \n",
    "    for i in range(0, num_records): \n",
    "        item[i] = {}\n",
    "        item[i]['item_category-item_name'] = np.random.choice(category_item)\n",
    "        item[i]['item_condition'] = np.random.choice(item_condition)\n",
    "        item[i]['item_postcode'] = np.random.choice(postcodes_berlin_series)\n",
    "        item[i]['item_status'] = np.random.choice(item_status)\n",
    "        item[i]['user_lat-user_lng'] = polygon_random_points(poly,1)\n",
    "        item[i]['userwhochangeditemstatus_id'] = np.random.choice(user_id_series)\n",
    "        datetime_iteration1 = fake.date_between_dates(limit,'now')\n",
    "        datetime_iteration2 = fake.date_between_dates(limit,'now')\n",
    "        if datetime_iteration1 <= datetime_iteration2:\n",
    "            item[i]['item_datetime_posted'] = datetime_iteration1\n",
    "            item[i]['item_datetimechangeditemstatus'] = datetime_iteration2\n",
    "        else:\n",
    "            item[i]['item_datetime_posted'] = datetime_iteration2\n",
    "            item[i]['item_datetimechangeditemstatus'] = datetime_iteration1  \n",
    " # This date shold be later than the post\n",
    "        \n",
    "\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "7fd3f684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_category-item_name</th>\n",
       "      <th>item_condition</th>\n",
       "      <th>item_postcode</th>\n",
       "      <th>item_status</th>\n",
       "      <th>user_lat-user_lng</th>\n",
       "      <th>userwhochangeditemstatus_id</th>\n",
       "      <th>item_datetime_posted</th>\n",
       "      <th>item_datetimechangeditemstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>furniture-cabinet</td>\n",
       "      <td>bad</td>\n",
       "      <td>10179</td>\n",
       "      <td>avaliable</td>\n",
       "      <td>[POINT (52.51248619826432 13.57587095032318)]</td>\n",
       "      <td>24</td>\n",
       "      <td>2023-02-17</td>\n",
       "      <td>2023-02-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shoes-man_shoes</td>\n",
       "      <td>good</td>\n",
       "      <td>10317</td>\n",
       "      <td>not_available</td>\n",
       "      <td>[POINT (52.49582265281618 13.16530272130326)]</td>\n",
       "      <td>53</td>\n",
       "      <td>2023-03-05</td>\n",
       "      <td>2023-03-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>musical_equipment-contrabass</td>\n",
       "      <td>good</td>\n",
       "      <td>12047</td>\n",
       "      <td>not_available</td>\n",
       "      <td>[POINT (52.46024485098363 13.3163368358419)]</td>\n",
       "      <td>509</td>\n",
       "      <td>2023-03-04</td>\n",
       "      <td>2023-03-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lighting-lighting</td>\n",
       "      <td>medium</td>\n",
       "      <td>13583</td>\n",
       "      <td>avaliable</td>\n",
       "      <td>[POINT (52.5115786468483 13.18207418671305)]</td>\n",
       "      <td>986</td>\n",
       "      <td>2023-02-24</td>\n",
       "      <td>2023-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>miscelaneaous-frame</td>\n",
       "      <td>good</td>\n",
       "      <td>14053</td>\n",
       "      <td>avaliable</td>\n",
       "      <td>[POINT (52.57691985974373 13.34614095648883)]</td>\n",
       "      <td>485</td>\n",
       "      <td>2023-02-13</td>\n",
       "      <td>2023-03-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        item_category-item_name item_condition item_postcode    item_status  \\\n",
       "0             furniture-cabinet            bad         10179      avaliable   \n",
       "1               shoes-man_shoes           good         10317  not_available   \n",
       "2  musical_equipment-contrabass           good         12047  not_available   \n",
       "3             lighting-lighting         medium         13583      avaliable   \n",
       "4           miscelaneaous-frame           good         14053      avaliable   \n",
       "\n",
       "                               user_lat-user_lng userwhochangeditemstatus_id  \\\n",
       "0  [POINT (52.51248619826432 13.57587095032318)]                          24   \n",
       "1  [POINT (52.49582265281618 13.16530272130326)]                          53   \n",
       "2   [POINT (52.46024485098363 13.3163368358419)]                         509   \n",
       "3   [POINT (52.5115786468483 13.18207418671305)]                         986   \n",
       "4  [POINT (52.57691985974373 13.34614095648883)]                         485   \n",
       "\n",
       "  item_datetime_posted item_datetimechangeditemstatus  \n",
       "0           2023-02-17                     2023-02-18  \n",
       "1           2023-03-05                     2023-03-07  \n",
       "2           2023-03-04                     2023-03-07  \n",
       "3           2023-02-24                     2023-03-04  \n",
       "4           2023-02-13                     2023-03-01  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_mock_df = pd.DataFrame(create_item_data(100)).transpose()\n",
    "item_mock_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34f26e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a4d903d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_mock_df['item_id'] = item_mock_df.index +1  # add item_id\n",
    "item_id_series = item_mock_df['item_id']  # storage in a variable to use later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68bbff6",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "86c54413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to create model data\n",
    "\n",
    "\n",
    "def create_model_data(num_records): \n",
    "  \n",
    "    # dictionary \n",
    "    model ={} \n",
    "    for i in range(0, num_records): \n",
    "        model[i] = {} \n",
    "        model[i]['item_id'] = np.random.choice(item_id_series)\n",
    "        model[i]['item_category-item_name'] = np.random.choice(category_item)\n",
    "        model[i]['item_condition'] = np.random.choice(item_condition)\n",
    "        model[i]['item_lat-item_lng'] = polygon_random_points(poly,1)\n",
    "        model[i]['item_postcode'] = np.random.choice(postcodes_berlin_series)\n",
    "        model[i]['item_status'] = np.random.choice(item_status)\n",
    "        model[i]['userwhoposted_id'] = np.random.choice(user_id_series)\n",
    "        model[i]['userwhopickedup_id'] = np.random.choice(user_id_series)\n",
    "        model[i]['userwhochangeditemstatus_id'] = np.random.choice(user_id_series)\n",
    "        model[i]['userwhochangeditemstatus_lat-userwhochangeditemstatus_lng'] = polygon_random_points(poly,1)\n",
    "        model[i]['searched_item_name-searched_item_category-searched_item'] = np.random.choice(category_item)\n",
    "        model[i]['searched_postcode'] = np.random.choice(postcodes_berlin_series)\n",
    "        datetime_iteration1 = fake.date_between_dates(limit,'now')\n",
    "        datetime_iteration2 = fake.date_between_dates(limit,'now')\n",
    "        if datetime_iteration1 <= datetime_iteration2:\n",
    "            model[i]['item_datetime_posted'] = datetime_iteration1\n",
    "            model[i]['item_datetimechangeditemstatus'] = datetime_iteration2\n",
    "        else:\n",
    "            model[i]['item_datetime_posted'] = datetime_iteration2\n",
    "            model[i]['item_datetimechangeditemstatus'] = datetime_iteration1  \n",
    "       \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "54c6d6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 14)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mock_df = pd.DataFrame(create_model_data(1000)).transpose()\n",
    "# model_mock_df.head(5)\n",
    "model_mock_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "ab16fe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 0 to 999\n",
      "Data columns (total 14 columns):\n",
      " #   Column                                                     Non-Null Count  Dtype \n",
      "---  ------                                                     --------------  ----- \n",
      " 0   item_id                                                    1000 non-null   object\n",
      " 1   item_category-item_name                                    1000 non-null   object\n",
      " 2   item_condition                                             1000 non-null   object\n",
      " 3   item_lat-item_lng                                          1000 non-null   object\n",
      " 4   item_postcode                                              1000 non-null   object\n",
      " 5   item_status                                                1000 non-null   object\n",
      " 6   userwhoposted_id                                           1000 non-null   object\n",
      " 7   userwhopickedup_id                                         1000 non-null   object\n",
      " 8   userwhochangeditemstatus_id                                1000 non-null   object\n",
      " 9   userwhochangeditemstatus_lat-userwhochangeditemstatus_lng  1000 non-null   object\n",
      " 10  searched_item_name-searched_item_category-searched_item    1000 non-null   object\n",
      " 11  searched_postcode                                          1000 non-null   object\n",
      " 12  item_datetime_posted                                       1000 non-null   object\n",
      " 13  item_datetimechangeditemstatus                             1000 non-null   object\n",
      "dtypes: object(14)\n",
      "memory usage: 117.2+ KB\n"
     ]
    }
   ],
   "source": [
    "model_mock_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c1e7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ac0601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a56ff90",
   "metadata": {},
   "source": [
    "### Split columns of dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "88bb3b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mock_df[['item_category','item_name']] = model_mock_df['item_category-item_name'].apply(lambda x: pd.Series(str(x).split(\"-\")))\n",
    "\n",
    "model_mock_df[['searched_item_name','item_category-searched_item']] = model_mock_df['searched_item_name-searched_item_category-searched_item'].apply(lambda x: pd.Series(str(x).split(\"-\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6907a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b98234",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bb2af26",
   "metadata": {},
   "source": [
    "# CONTINUE FROM HERE"
   ]
  },
  {
   "cell_type": "raw",
   "id": "158e6c7f",
   "metadata": {},
   "source": [
    "df['lon'] = df.point_object.x\n",
    "df['lat'] = df.point_object.y\n",
    "OR\n",
    "df['lon'] = df.point_object.apply(lambda p: p.x)\n",
    "df['lat'] = df.point_object.apply(lambda p: p.y)\n",
    "\n",
    "https://stackoverflow.com/questions/49635436/shapely-point-geometry-in-geopandas-df-to-lat-lon-columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0ca8fb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # model_mock_df['item_lat-item_lng']\n",
    "# model_mock_df['lon'] = model_mock_df.point_object.apply(lambda p: p.x)\n",
    "# model_mock_df['lat'] = model_mock_df.point_object.apply(lambda p: p.y)\n",
    "\n",
    "\n",
    "# # [8:-3]\n",
    "# # 0 to 8\n",
    "# # -3 to -19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eb746c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "8958bade",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[229], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 'item_lat-item_lng'\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model_mock_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_lat\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_lng\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m model_mock_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_lat-item_lng\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: pd\u001b[38;5;241m.\u001b[39mSeries(\u001b[38;5;28mstr\u001b[39m(x)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 'userwhochangeditemstatus_lat-userwhochangeditemstatus_lng'\u001b[39;00m\n\u001b[1;32m      6\u001b[0m model_mock_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muserwhochangeditemstatus_lat\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muserwhochangeditemstatus_lng\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m model_mock_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muserwhochangeditemstatus_lat-userwhochangeditemstatus_lng\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: pd\u001b[38;5;241m.\u001b[39mSeries(\u001b[38;5;28mstr\u001b[39m(x)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ds_geofree/lib/python3.10/site-packages/pandas/core/frame.py:3966\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3964\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_frame(key, value)\n\u001b[1;32m   3965\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (Series, np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mlist\u001b[39m, Index)):\n\u001b[0;32m-> 3966\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3967\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m   3968\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item_frame_value(key, value)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ds_geofree/lib/python3.10/site-packages/pandas/core/frame.py:4008\u001b[0m, in \u001b[0;36mDataFrame._setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4003\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4004\u001b[0m     \u001b[38;5;66;03m# Note: unlike self.iloc[:, indexer] = value, this will\u001b[39;00m\n\u001b[1;32m   4005\u001b[0m     \u001b[38;5;66;03m#  never try to overwrite values inplace\u001b[39;00m\n\u001b[1;32m   4007\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[0;32m-> 4008\u001b[0m         \u001b[43mcheck_key_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4009\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k1, k2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(key, value\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[1;32m   4010\u001b[0m             \u001b[38;5;28mself\u001b[39m[k1] \u001b[38;5;241m=\u001b[39m value[k2]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ds_geofree/lib/python3.10/site-packages/pandas/core/indexers/utils.py:401\u001b[0m, in \u001b[0;36mcheck_key_length\u001b[0;34m(columns, key, value)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m columns\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(key):\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns must be same length as key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;66;03m# Missing keys in columns are represented as -1\u001b[39;00m\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(key)[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mcolumns):\n",
      "\u001b[0;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "\n",
    "# # 'item_lat-item_lng'\n",
    "# model_mock_df[['item_lat','item_lng']] = model_mock_df['item_lat-item_lng'].apply(lambda x: pd.Series(str(x).split(\"-\")))\n",
    "\n",
    "\n",
    "# # 'userwhochangeditemstatus_lat-userwhochangeditemstatus_lng'\n",
    "# model_mock_df[['userwhochangeditemstatus_lat','userwhochangeditemstatus_lng']] = model_mock_df['userwhochangeditemstatus_lat-userwhochangeditemstatus_lng'].apply(lambda x: pd.Series(str(x).split(\"-\")))\n",
    "\n",
    "\n",
    "# model_mock_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "fc05c565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 0 to 999\n",
      "Data columns (total 18 columns):\n",
      " #   Column                                                     Non-Null Count  Dtype \n",
      "---  ------                                                     --------------  ----- \n",
      " 0   item_id                                                    1000 non-null   object\n",
      " 1   item_category-item_name                                    1000 non-null   object\n",
      " 2   item_condition                                             1000 non-null   object\n",
      " 3   item_lat-item_lng                                          1000 non-null   object\n",
      " 4   item_postcode                                              1000 non-null   object\n",
      " 5   item_status                                                1000 non-null   object\n",
      " 6   userwhoposted_id                                           1000 non-null   object\n",
      " 7   userwhopickedup_id                                         1000 non-null   object\n",
      " 8   userwhochangeditemstatus_id                                1000 non-null   object\n",
      " 9   userwhochangeditemstatus_lat-userwhochangeditemstatus_lng  1000 non-null   object\n",
      " 10  searched_item_name-searched_item_category-searched_item    1000 non-null   object\n",
      " 11  searched_postcode                                          1000 non-null   object\n",
      " 12  item_datetime_posted                                       1000 non-null   object\n",
      " 13  item_datetimechangeditemstatus                             1000 non-null   object\n",
      " 14  item_category                                              1000 non-null   object\n",
      " 15  item_name                                                  1000 non-null   object\n",
      " 16  searched_item_name                                         1000 non-null   object\n",
      " 17  item_category-searched_item                                1000 non-null   object\n",
      "dtypes: object(18)\n",
      "memory usage: 148.4+ KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_mock_df.info(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "0b2df498",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[232], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# points_item = model_mock_df['item_lat-item_lng'] \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# list_item_lat_lng = model_mock_df['item_lat-item_lng'] \u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model_mock_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_lat-item_lng\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m,p\u001b[38;5;241m.\u001b[39my)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'x'"
     ]
    }
   ],
   "source": [
    "# points_item = model_mock_df['item_lat-item_lng'] \n",
    "\n",
    "# list_item_lat_lng = model_mock_df['item_lat-item_lng'] \n",
    "    \n",
    "for p in model_mock_df['item_lat-item_lng']:\n",
    "    print(p.x,\",\",p.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba470965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b651f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a final dataset\n",
    "columns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf087f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fd341b1",
   "metadata": {},
   "source": [
    "### Creating csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dc7432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f29b14c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_mock_df.to_csv('data/user_mock_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "25b5c1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_mock_df.to_csv('data/item_mock_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "96b21495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_mock_df.to_csv('data/model_mock_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28334203",
   "metadata": {},
   "source": [
    "## References:\n",
    "- [Generate custom datasets using Python Faker](https://blogs.sap.com/2021/05/26/generate-custom-datasets-using-python-faker/)\n",
    "- [folium_polygon_rectangle_layers](https://www.youtube.com/watch?v=9E9FTJrOJ1E&t=752s)\n",
    "- [Faker](https://github.com/joke2k/faker/issues/1183)\n",
    "- [Generating Mock Data with Python! (NumPy, Pandas, & Datetime Libraries)](https://www.youtube.com/watch?v=VJBY2eVtf7o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76c7ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
