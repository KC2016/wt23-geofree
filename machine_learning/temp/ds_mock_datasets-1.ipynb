{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0ff3309",
   "metadata": {},
   "source": [
    "# Creating a MOCK dataset\n",
    "__________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8be3b9",
   "metadata": {},
   "source": [
    "The process to create a fake dataset started by making dataframes about `users` and `item`, and further a complete dataframe that could be used in the `model`.\n",
    "\n",
    "`numpy random` and `faker` were used to ccreate randomized series. Latutude_longitude points were picked using a polygons method, consideing four points choosen manually in Google Maps.\n",
    "\n",
    "Dependent variables are part of a same series, identified by underscore.\n",
    "\n",
    "Addresses are illustrative, they are addresses from all over Germany. This is a limitation of the Faker package, which only considers countries, and does not have data for Berlin.\n",
    "\n",
    "_________________________________\n",
    "\n",
    "## Questions:\n",
    "- HOW LONG DO THE ITEMS GET IN THE APP? (IF NOBODY CHANGE ITS STATUS?) WHAT ABOUT 7 DAYS?\n",
    "\n",
    "_________________________________\n",
    "\n",
    "### TODOs:\n",
    "- ADD WEIGHT FOR VALUES? I decided to web scrape [Free Your Stuff Berlin]\n",
    "- ADD BLANKS?\n",
    "- COULD HAVE: FIND AND API FOR ADDRESSES IN BERLIN\n",
    "- COULD HAVE: DOWNLOAD PICTURES USING API: https://unsplash.com/developers or scrape the website free your stuff berliin.\n",
    "- COULD HAVE: Create a data frame with item_id and item_picture\n",
    "_________________________________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5066ea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "from faker import Faker, providers\n",
    "from faker.providers.address.de_DE import Provider as DeDeAddressProvider\n",
    "from faker.generator import random\n",
    "from faker.providers import BaseProvider\n",
    "# import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75af7841",
   "metadata": {},
   "source": [
    "### Postcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10760793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xs/pmxwbppj14b4v76l4llp17n80000gp/T/ipykernel_92805/4224319896.py:4: FutureWarning: DataFrame.set_axis 'inplace' keyword is deprecated and will be removed in a future version. Use `obj = obj.set_axis(..., copy=False)` instead\n",
      "  df.set_axis([\"postcodes_berlin\"], axis=1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# immport and clean original dataset removing poostcodes from Germanay, that are not in Berlin\n",
    "postcodes_de = pd.read_excel(r'ds_mock_datasets/data/German-Zip-Codes.xlsx', sheet_name='Berlin')\n",
    "df = pd.DataFrame(postcodes_de)\n",
    "df.set_axis([\"postcodes_berlin\"], axis=1,inplace=True)\n",
    "df = (df[\"postcodes_berlin\"].str[8:-11])\n",
    "df.to_csv('ds_mock_datasets/data/postcodes_berlin.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93845160",
   "metadata": {},
   "source": [
    "### Creating the postcode series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5c4f1a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/postcodes_berlin.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xs/pmxwbppj14b4v76l4llp17n80000gp/T/ipykernel_92805/969150637.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import postcodes from Berlin and create a dataframe removing indexes and headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpostcodes_berlin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/postcodes_berlin.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpostcodes_berlin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpostcodes_berlin_series\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpostcodes_berlin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ds_geofree/lib/python3.10/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ds_geofree/lib/python3.10/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ds_geofree/lib/python3.10/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ds_geofree/lib/python3.10/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ds_geofree/lib/python3.10/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ds_geofree/lib/python3.10/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ds_geofree/lib/python3.10/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/postcodes_berlin.csv'"
     ]
    }
   ],
   "source": [
    "# import postcodes from Berlin and create a dataframe removing indexes and headers\n",
    "postcodes_berlin = pd.read_csv('data/postcodes_berlin.csv')\n",
    "print(postcodes_berlin)\n",
    "postcodes_berlin_series = postcodes_berlin[:][1:].squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501abd94",
   "metadata": {},
   "source": [
    "### Creating lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93059002",
   "metadata": {},
   "source": [
    "#### lat lng : choosing random point based on a polygon\n",
    "reference: \n",
    "    A quick trick to create random lat/long coordinates in python (within a defined polygon)\n",
    "https://medium.com/the-data-journal/a-quick-trick-to-create-random-lat-long-coordinates-in-python-within-a-defined-polygon-e8997f05123a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6152d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Modules\n",
    "import numpy as np\n",
    "import random\n",
    "# Use 'conda install shapely' to import the shapely library.\n",
    "from shapely.geometry import Polygon, Point\n",
    "\n",
    "num_records = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc658e66",
   "metadata": {},
   "source": [
    "### Creating the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fab278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: # multi_locale_generator = Faker(['it_IT', 'en_US', 'de-DE', 'pt_BR', 'es-ES', 'fr-FR', 'ru-RU', 'tr-TR'])\n",
    "\n",
    "# Instantiate Faker with multiple locales\n",
    "german_locale_generator = Faker(['de_DE'])\n",
    "fake = Faker()\n",
    "Faker.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d3c6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  First code, I improved it \n",
    "\n",
    "# user_mock_df = pd.DataFrame({'user_name': [german_locale_generator.name() for i in range(num_records)],\n",
    "#                              'user_email': [german_locale_generator.email() for i in range(num_records)],\n",
    "#                              'user_address': [german_locale_generator.address() for i in range(num_records)],\n",
    "#                              'user_type': [random.choices(user_type, k=1) for i in range(num_records)],\n",
    "#                              'user_lat_lng': [polygon_random_points(poly,1) for i in range(num_records)]\n",
    "#                               })\n",
    "\n",
    "# item_mock_df = pd.DataFrame({'item_name-item_category':[random.choices(category_item, k=1) for i in range(num_records)],\n",
    "#                             'item_postcode': [random.choices(postcodes_berlin_series, k=1) for i in range(num_records)],\n",
    "#                             'item_status': [random.choices(item_status, k=1) for i in range(num_records)],\n",
    "#                             'item_lat_lng': [polygon_random_points(poly,1) for i in range(num_records)],\n",
    "#                             'item_datetime_posted': [german_locale_generator.date_time_this_year() for i in range(num_records)],\n",
    "# #                             'item_datetime_statuschanged': \n",
    "# #                              'userwhochangeditemstatus_id': \n",
    "                             \n",
    "#                              })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f926b4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the desired polygon : points choosen in Google maps\n",
    "\n",
    "poly = Polygon([(52.645883, 13.395869), \n",
    "                (52.526568, 13.645808),\n",
    "                (52.381789, 13.405482),\n",
    "                (52.484773, 13.136317)])\n",
    "\n",
    "\n",
    "min_x = 52.381789\n",
    "max_x = 52.645883\n",
    "min_y = 13.136317\n",
    "max_y = 13.645808\n",
    "\n",
    "# Defining the randomization generator\n",
    "def polygon_random_points (poly, num_records):\n",
    "    min_x, min_y, max_x, max_y = poly.bounds\n",
    "    points = []\n",
    "    while len(points) < num_records:\n",
    "        random_point = Point([random.uniform(min_x, max_x), random.uniform(min_y, max_y)])\n",
    "        if (random_point.within(poly)):\n",
    "            points.append(random_point)\n",
    "    return points\n",
    "    # Choose the number of points desired. T\\ \n",
    "points = polygon_random_points(poly,num_records)\n",
    "# Testing the results.\n",
    "for p in points:\n",
    "    print(p.x,\",\",p.y)\n",
    "                             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25096f71",
   "metadata": {},
   "source": [
    "### User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2606e7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to create user data\n",
    "\n",
    "user_type = ['giver', 'looker']\n",
    "\n",
    "\n",
    "def create_user_data(num_records): \n",
    "  \n",
    "    # dictionary \n",
    "    user ={} \n",
    "    for i in range(0, num_records): \n",
    "        user[i] = {} \n",
    "        user[i]['name'] = fake.name()\n",
    "#         user[i]['email'] = fake.email()\n",
    "#         user[i]['email'] = fake.ascii_free_email()\n",
    "        user[i]['email'] = fake.ascii_email()\n",
    "        user[i]['address'] = german_locale_generator.address()  # these addresses are from germany, find a list of address for berlin\n",
    "        user[i]['user_type'] = fake.random_element(user_type)\n",
    "        user[i]['user_lat_lng'] = polygon_random_points(poly,1)\n",
    "        user[i]['user_postcode'] = np.random.choice(postcodes_berlin_series)\n",
    "\n",
    "    return user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a27923",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mock_df = pd.DataFrame(create_user_data(1000)).transpose()\n",
    "user_mock_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0feb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add user_ids \n",
    "user_mock_df['user_id'] = user_mock_df.index + 1\n",
    "user_id_series = user_mock_df['user_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65da01d1",
   "metadata": {},
   "source": [
    "### Item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d154b713",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_status = ['avaliable', 'not_available']\n",
    "item_condition = ['good_condition','medium_condition''bad_condition']\n",
    "\n",
    "category_item = ['furniture-sofa'\n",
    "                 'furniture-armchair',\n",
    "                 'furniture-chair',\n",
    "                 'furniture-table',\n",
    "                 'furniture-bed',\n",
    "                 'furniture-bookcase',\n",
    "                 'furniture-bedside_table',\n",
    "                 'furniture-cabinet',\n",
    "                 'furniture-rollcontainers',\n",
    "                 'furniture-shoe_rack',\n",
    "                 'furniture-mirror',\n",
    "                 'furniture-cot',\n",
    "                 'appliance-washing_machine',\n",
    "                 'appliance-dish_washer',\n",
    "                 'appliance-drying_rack',\n",
    "                 'appliance-refrigerator',\n",
    "                 'appliance-blender',\n",
    "                 'appliance-extractor_hood',\n",
    "                 'appliance-clothes_iron',\n",
    "                 'appliance-vacuum_cleaner',\n",
    "                 'appliance-sandwich_maker',\n",
    "                 'appliance-kettle',\n",
    "                 'appliance-air_conditioner',\n",
    "                 'appliance-heater',\n",
    "                 'appliance-pan',\n",
    "                 'appliance-popcorn_maker',\n",
    "                 'appliance-coffee_machine',\n",
    "                 'appliance-stove',\n",
    "                 'lighting-lighting',\n",
    "                 'lighting-chandelier',\n",
    "                 'lighting-lightbulb',\n",
    "                 'musical_equipment-guitar',\n",
    "                 'musical_equipment-sound_amplifier',\n",
    "                 'musical_equipment-contrabass',\n",
    "                 'musical_equipment-battery',\n",
    "                 'musical_equipment-piano',\n",
    "                 'tech-desktop',\n",
    "                 'tech-laptop',\n",
    "                 'tech-phone',\n",
    "                 'tech-keyboard',\n",
    "                 'clothes-woman_jacket',\n",
    "                 'clothes-man_jacket',\n",
    "                 'clothes-child_jacket',\n",
    "                 'clothes-woman_clothes',\n",
    "                 'clothes-man_clothes',\n",
    "                 'clothes-child_clothes',\n",
    "                 'shoes-woman_shoes',\n",
    "                 'shoes-manshoes',\n",
    "                 'shoes-child_shoes',\n",
    "                 'miscelaneaous-ironing_board',\n",
    "                 'miscelaneaous-baby_carriage',\n",
    "                 'miscelaneaous-picture_frame',\n",
    "                 'miscelaneaous-bicycle',\n",
    "                 'miscelaneaous-plant',\n",
    "                 'miscelaneaous-carpet',\n",
    "                 'miscelaneaous-roller_skates',\n",
    "                 'miscelaneaous-ski_skates',\n",
    "                 'miscelaneaous-books']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850728a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to create item data\n",
    "\n",
    "def create_item_data(num_records): \n",
    "  \n",
    "    # dictionary \n",
    "    item ={} \n",
    "    for i in range(0, num_records): \n",
    "        item[i] = {}\n",
    "        item[i]['item_name-item_category'] = np.random.choice(category_item)\n",
    "        item[i]['item_condition'] = np.random.choice(item_condition)\n",
    "        item[i]['item_postcode'] = np.random.choice(postcodes_berlin_series)\n",
    "        item[i]['item_status'] = np.random.choice(item_status)\n",
    "        item[i]['user_lat_lng'] = polygon_random_points(poly,1)\n",
    "        item[i]['userwhochangeditemstatus_id'] = np.random.choice(user_id_series)\n",
    "        datetime_iteration1 = fake.date_between_dates('-7d','now')\n",
    "        datetime_iteration2 = fake.date_between_dates('-7d','now')\n",
    "        if datetime_iteration1 <= datetime_iteration2:\n",
    "            item[i]['item_datetime_posted'] = datetime_iteration1\n",
    "            item[i]['item_datetimechangeditemstatus'] = datetime_iteration2\n",
    "        else:\n",
    "            item[i]['item_datetime_posted'] = datetime_iteration2\n",
    "            item[i]['item_datetimechangeditemstatus'] = datetime_iteration1  \n",
    " # This date shold be later than the post\n",
    "        \n",
    "\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd3f684",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_mock_df = pd.DataFrame(create_item_data(1000)).transpose()\n",
    "item_mock_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd206650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_mock_df = pd.DataFrame({'item_name-item_category':[random.choices(category_name, k=1) for i in range(num_records)],\n",
    "#                             'item_postcode': [random.choices(postcodes_berlin_series, k=1) for i in range(num_records)],\n",
    "#                             'item_status': [random.choices(item_status, k=1) for i in range(num_records)],\n",
    "#                             'item_lat_lng': [polygon_random_points(poly,1) for i in range(num_records)],\n",
    "#                             'item_datetime_posted': [german_locale_generator.date_time_this_year() for i in range(num_records)],\n",
    "# #                             'item_datetime_statuschanged': \n",
    "# #                              'userwhochangeditemstatus_id': \n",
    "#                              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d903d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_mock_df['item_id'] = item_mock_df.index +1  # add item_id\n",
    "item_id_series = item_mock_df['item_id']  # storage in a variable to use later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68bbff6",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c54413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to create model data\n",
    "\n",
    "def create_model_data(num_records): \n",
    "  \n",
    "    # dictionary \n",
    "    model ={} \n",
    "    for i in range(0, num_records): \n",
    "        model[i] = {} \n",
    "        model[i]['item_id'] = np.random.choice(item_id_series)\n",
    "        model[i]['item_name-item_category-item'] = np.random.choice(category_item)\n",
    "        model[i]['item_condition'] = np.random.choice(item_condition)\n",
    "        model[i]['item_lat_lng'] = polygon_random_points(poly,1)\n",
    "        model[i]['item_postcode'] = np.random.choice(postcodes_berlin_series)\n",
    "        model[i]['item_status'] = np.random.choice(item_status)\n",
    "        model[i]['userwhoposted_id'] = np.random.choice(user_id_series)\n",
    "        model[i]['userwhopickedup_id'] = np.random.choice(user_id_series)\n",
    "        model[i]['userwhochangeditemstatus_id'] = np.random.choice(user_id_series)\n",
    "        model[i]['userwhochangeditemstatus_lat_lng'] = polygon_random_points(poly,1)\n",
    "        model[i]['searched_item_name-searched_item_category-searched_item'] = np.random.choice(category_item)\n",
    "        model[i]['searched_postcode'] = np.random.choice(postcodes_berlin_series)\n",
    "        datetime_iteration1 = fake.date_between_dates('-7d','now')\n",
    "        datetime_iteration2 = fake.date_between_dates('-7d','now')\n",
    "        if datetime_iteration1 <= datetime_iteration2:\n",
    "            model[i]['item_datetime_posted'] = datetime_iteration1\n",
    "            model[i]['item_datetimechangeditemstatus'] = datetime_iteration2\n",
    "        else:\n",
    "            model[i]['item_datetime_posted'] = datetime_iteration2\n",
    "            model[i]['item_datetimechangeditemstatus'] = datetime_iteration1  \n",
    "       \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c6d6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mock_df = pd.DataFrame(create_model_data(1000)).transpose()\n",
    "model_mock_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0d1647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item_id_series = item_mock_df['item_id']\n",
    "# user_id_series = user_mock_df['user_id']\n",
    "\n",
    "# for_model_mock_df = pd.DataFrame({'item_id': [random.choices(item_id_series, k=1) for i in range(num_records)],\n",
    "#                                   'item_name-item_category': [random.choices(category_item, k=1) for i in range(num_records)],  \n",
    "#                                   'item_lat_lng': [polygon_random_points(poly,1) for i in range(num_records)], \n",
    "#                                   'item_postcode': [random.choices(postcodes_berlin_series, k=1) for i in range(num_records)], \n",
    "#                                   'item_status':\n",
    "#                                   'userwhoposted_id': [random.choices(user_id_series, k=1) for i in range(num_records)],\n",
    "#                                   'userwhopickedup_id': [random.choices(user_id_series, k=1) for i in range(num_records)], \n",
    "#                                   'userwhochangeditemstatus_id': [random.choices(user_id_series, k=1) for i in range(num_records)], \n",
    "#                                   'userwhochangeditemstatus_lat_lng': [polygon_random_points(poly,1) for i in range(num_records)],\n",
    "#                                   'searched_item_name-searched_item_category': [random.choices(category_item, k=1) for i in range(num_records)], \n",
    "#                                   'searched_postcode': [random.choices(postcodes_berlin_series, k=1) for i in range(num_records)],\n",
    "#                                   'item_datetime_posted': [german_locale_generator.date_time_this_year() for i in range(num_records)], \n",
    "# #                                   'item_datetime_statuschanged': [german_locale_generator.date_time_this_year() for i in range(num_records) if german_locale_generator.date_time_this_year() > item_datetime_posted]\n",
    "#                                   })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd341b1",
   "metadata": {},
   "source": [
    "### Creating csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29b14c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mock_df.to_csv('data/user_mock_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b5c1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_mock_df.to_csv('data/item_mock_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b21495",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mock_df.to_csv('data/model_mock_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59647923",
   "metadata": {},
   "source": [
    "### COULD HAVE:  Create a data frame with item_id and item_picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecf4955",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# item_picture_mock_df = pd.DataFrame({item_mock_df['item_id'].\n",
    "#                            'item_datetime_picture':\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28334203",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "- [Generate custom datasets using Python Faker](https://blogs.sap.com/2021/05/26/generate-custom-datasets-using-python-faker/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
